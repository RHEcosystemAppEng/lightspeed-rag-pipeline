apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  name: evaluation
spec:
  description: >-
    These task evaluate embedding file on for different llms  

  workspaces:
    - name: persist-source
      description: shared Workspace containing the data to embed
    - name: output
      description: evaluation
  params:
    - name: provider
      type: string
      description: name of provider [bam,openai]
      default: bam

    - name: model
      type: string
      description: model 
      default: local:BAAI/bge-base-en

    - name: product-index
      type: string
      description: storage product index
      default: product

    - name: input-persist-dir
      type: string
      description: path to persist file folder 
      default: "."

    - name: question-folder
      type: string
      description: plain text folder path used for question 


    - name: number-of-questions
      type: string
      description: vector db port  
      default: "5"

    - name: similarity
      type: string
      default: "5"
      description: authentication headers per vectorDB requirements 

  results:
    - name: status
      description: task status 
  steps:
    - name: evaluation
      image: "quay.io/ecosystem-appeng/rag-evaluation:26" # update image accordingly
      envFrom:
          - secretRef:
              name: secret-openai
          - secretRef:
              name: secret-bam

      env:
      - name: PROVIDER
        value: "$(params.provider)"
      - name: MODEL
        value: "$(params.model)"
      - name: PRODUCT_INDEX
        value: $(params.product-index)
      - name: INPUT-PERSIST-DIR
        value: $(params.input-persist-dir)
      - name: QUESTION_FOLDER
        value: $(params.question-folder)

      - name: SIMILARITY
        value: $(params.similarity)

      - name:  NUMBER-OF-QUESTIONS
        value: $(params.number-of-questions)

      - name: OUTPUT_PATH
        value: $(workspaces.output.path)/data

      - name: TOKENIZERS_PARALLELISM
        value: "false"
      script: |
        #!/usr/bin/env sh
        set -eu

        python evaluation.py --provider ${PROVIDER} \
                              --input-persist-dir ${INPUT-PERSIST-DIR} \ 
                              --pi ${PRODUCT_INDEX} \
                              --model ${MODEL} \
                              -o ${OUTPUT_PATH} \
                              --question-folder ${QUESTION_FOLDER}\
                              -s ${SIMILARITY} \
                              -qn ${NUMBER-OF-QUESTIONS}

        mv ${WORKSPACE_OUTPUT_PATH}/*.md $(workspaces.output.path)

